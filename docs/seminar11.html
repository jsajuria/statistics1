<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistics 1</title>
  <meta name="description" content="Statistics 1">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistics 1" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistics 1" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="seminar10.html">
<link rel="next" href="datacamp.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="lib/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="js/codefolding.js"></script>


<script>
$(document).ready(function () {
  window.initializeCodeFolding();
});
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="lib\bootstrap\3.3.7\css\bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="css\readthedocs.css" type="text/css" />
<link rel="stylesheet" href="css\custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this course</a></li>
<li class="chapter" data-level="1" data-path="seminar1.html"><a href="seminar1.html"><i class="fa fa-check"></i><b>1</b> Introduction: Measurement, Central Tendency, Dispersion, Validity, Reliability</a><ul>
<li class="chapter" data-level="1.1" data-path="seminar1.html"><a href="seminar1.html#seminar"><i class="fa fa-check"></i><b>1.1</b> Seminar</a><ul>
<li class="chapter" data-level="1.1.1" data-path="seminar1.html"><a href="seminar1.html#getting-started"><i class="fa fa-check"></i><b>1.1.1</b> Getting Started</a></li>
<li class="chapter" data-level="1.1.2" data-path="seminar1.html"><a href="seminar1.html#rstudio"><i class="fa fa-check"></i><b>1.1.2</b> RStudio</a></li>
<li class="chapter" data-level="1.1.3" data-path="seminar1.html"><a href="seminar1.html#console"><i class="fa fa-check"></i><b>1.1.3</b> Console</a></li>
<li class="chapter" data-level="1.1.4" data-path="seminar1.html"><a href="seminar1.html#functions"><i class="fa fa-check"></i><b>1.1.4</b> Functions</a></li>
<li class="chapter" data-level="1.1.5" data-path="seminar1.html"><a href="seminar1.html#getting-help"><i class="fa fa-check"></i><b>1.1.5</b> Getting Help</a></li>
<li class="chapter" data-level="1.1.6" data-path="seminar1.html"><a href="seminar1.html#the-assignment-operator"><i class="fa fa-check"></i><b>1.1.6</b> The Assignment Operator</a></li>
<li class="chapter" data-level="1.1.7" data-path="seminar1.html"><a href="seminar1.html#sequences"><i class="fa fa-check"></i><b>1.1.7</b> Sequences</a></li>
<li class="chapter" data-level="1.1.8" data-path="seminar1.html"><a href="seminar1.html#scripts"><i class="fa fa-check"></i><b>1.1.8</b> Scripts</a></li>
<li class="chapter" data-level="1.1.9" data-path="seminar1.html"><a href="seminar1.html#central-tendency"><i class="fa fa-check"></i><b>1.1.9</b> Central Tendency</a></li>
<li class="chapter" data-level="1.1.10" data-path="seminar1.html"><a href="seminar1.html#dispersion"><i class="fa fa-check"></i><b>1.1.10</b> Dispersion</a></li>
<li class="chapter" data-level="1.1.11" data-path="seminar1.html"><a href="seminar1.html#exercises"><i class="fa fa-check"></i><b>1.1.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="solutions1.html"><a href="solutions1.html"><i class="fa fa-check"></i><b>1.2</b> Solutions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="solutions1.html"><a href="solutions1.html#exercise-3"><i class="fa fa-check"></i><b>1.2.1</b> Exercise 3</a></li>
<li class="chapter" data-level="1.2.2" data-path="solutions1.html"><a href="solutions1.html#exercise-4"><i class="fa fa-check"></i><b>1.2.2</b> Exercise 4</a></li>
<li class="chapter" data-level="1.2.3" data-path="solutions1.html"><a href="solutions1.html#exercise-5"><i class="fa fa-check"></i><b>1.2.3</b> Exercise 5</a></li>
<li class="chapter" data-level="1.2.4" data-path="solutions1.html"><a href="solutions1.html#exercise-6"><i class="fa fa-check"></i><b>1.2.4</b> Exercise 6</a></li>
<li class="chapter" data-level="1.2.5" data-path="solutions1.html"><a href="solutions1.html#exercise-7"><i class="fa fa-check"></i><b>1.2.5</b> Exercise 7</a></li>
<li class="chapter" data-level="1.2.6" data-path="solutions1.html"><a href="solutions1.html#exercise-8"><i class="fa fa-check"></i><b>1.2.6</b> Exercise 8</a></li>
<li class="chapter" data-level="1.2.7" data-path="solutions1.html"><a href="solutions1.html#exercise-9"><i class="fa fa-check"></i><b>1.2.7</b> Exercise 9</a></li>
<li class="chapter" data-level="1.2.8" data-path="solutions1.html"><a href="solutions1.html#exercise-10"><i class="fa fa-check"></i><b>1.2.8</b> Exercise 10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="seminar2.html"><a href="seminar2.html"><i class="fa fa-check"></i><b>2</b> Research Design, Counterfactuals, Forming Hypotheses</a><ul>
<li class="chapter" data-level="2.1" data-path="seminar2.html"><a href="seminar2.html#seminar-1"><i class="fa fa-check"></i><b>2.1</b> Seminar</a><ul>
<li class="chapter" data-level="2.1.1" data-path="seminar2.html"><a href="seminar2.html#setting-up"><i class="fa fa-check"></i><b>2.1.1</b> setting up</a></li>
<li class="chapter" data-level="2.1.2" data-path="seminar2.html"><a href="seminar2.html#vectors-and-subsetting"><i class="fa fa-check"></i><b>2.1.2</b> vectors and subsetting</a></li>
<li class="chapter" data-level="2.1.3" data-path="seminar2.html"><a href="seminar2.html#data-frames"><i class="fa fa-check"></i><b>2.1.3</b> data frames</a></li>
<li class="chapter" data-level="2.1.4" data-path="seminar2.html"><a href="seminar2.html#loading-data"><i class="fa fa-check"></i><b>2.1.4</b> Loading data</a></li>
<li class="chapter" data-level="2.1.5" data-path="seminar2.html"><a href="seminar2.html#plots"><i class="fa fa-check"></i><b>2.1.5</b> Plots</a></li>
<li class="chapter" data-level="2.1.6" data-path="seminar2.html"><a href="seminar2.html#average-treatment-effect"><i class="fa fa-check"></i><b>2.1.6</b> Average Treatment Effect</a></li>
<li class="chapter" data-level="2.1.7" data-path="seminar2.html"><a href="seminar2.html#exercises-1"><i class="fa fa-check"></i><b>2.1.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="solutions2.html"><a href="solutions2.html"><i class="fa fa-check"></i><b>2.2</b> Solutions</a><ul>
<li class="chapter" data-level="2.2.1" data-path="solutions2.html"><a href="solutions2.html#exercise-2"><i class="fa fa-check"></i><b>2.2.1</b> Exercise 2</a></li>
<li class="chapter" data-level="2.2.2" data-path="solutions2.html"><a href="solutions2.html#exercise-3-1"><i class="fa fa-check"></i><b>2.2.2</b> Exercise 3</a></li>
<li class="chapter" data-level="2.2.3" data-path="solutions2.html"><a href="solutions2.html#exercise-4-1"><i class="fa fa-check"></i><b>2.2.3</b> Exercise 4</a></li>
<li class="chapter" data-level="2.2.4" data-path="solutions2.html"><a href="solutions2.html#exercise-5-1"><i class="fa fa-check"></i><b>2.2.4</b> Exercise 5</a></li>
<li class="chapter" data-level="2.2.5" data-path="solutions2.html"><a href="solutions2.html#exercise-6-1"><i class="fa fa-check"></i><b>2.2.5</b> Exercise 6</a></li>
<li class="chapter" data-level="2.2.6" data-path="solutions2.html"><a href="solutions2.html#exercise-7-1"><i class="fa fa-check"></i><b>2.2.6</b> Exercise 7</a></li>
<li class="chapter" data-level="2.2.7" data-path="solutions2.html"><a href="solutions2.html#exercise-8-1"><i class="fa fa-check"></i><b>2.2.7</b> Exercise 8</a></li>
<li class="chapter" data-level="2.2.8" data-path="solutions2.html"><a href="solutions2.html#exercises-9-and-10"><i class="fa fa-check"></i><b>2.2.8</b> Exercises 9 and 10</a></li>
<li class="chapter" data-level="2.2.9" data-path="solutions2.html"><a href="solutions2.html#exercises-11"><i class="fa fa-check"></i><b>2.2.9</b> Exercises 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="seminar3.html"><a href="seminar3.html"><i class="fa fa-check"></i><b>3</b> Sampling and Distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="seminar3.html"><a href="seminar3.html#seminar-2"><i class="fa fa-check"></i><b>3.1</b> Seminar</a><ul>
<li class="chapter" data-level="3.1.1" data-path="seminar3.html"><a href="seminar3.html#loading-dataset-in-csv-format"><i class="fa fa-check"></i><b>3.1.1</b> Loading Dataset in CSV Format</a></li>
<li class="chapter" data-level="3.1.2" data-path="seminar3.html"><a href="seminar3.html#missing-values"><i class="fa fa-check"></i><b>3.1.2</b> Missing Values</a></li>
<li class="chapter" data-level="3.1.3" data-path="seminar3.html"><a href="seminar3.html#factor-variables"><i class="fa fa-check"></i><b>3.1.3</b> Factor Variables</a></li>
<li class="chapter" data-level="3.1.4" data-path="seminar3.html"><a href="seminar3.html#renaming-variables"><i class="fa fa-check"></i><b>3.1.4</b> Renaming Variables</a></li>
<li class="chapter" data-level="3.1.5" data-path="seminar3.html"><a href="seminar3.html#distributions"><i class="fa fa-check"></i><b>3.1.5</b> Distributions</a></li>
<li class="chapter" data-level="3.1.6" data-path="seminar3.html"><a href="seminar3.html#conditional-distributions"><i class="fa fa-check"></i><b>3.1.6</b> Conditional Distributions</a></li>
<li class="chapter" data-level="3.1.7" data-path="seminar3.html"><a href="seminar3.html#exercises-2"><i class="fa fa-check"></i><b>3.1.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="solutions3.html"><a href="solutions3.html"><i class="fa fa-check"></i><b>3.2</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="seminar4.html"><a href="seminar4.html"><i class="fa fa-check"></i><b>4</b> T-test for Difference in Means and Hypothesis Testing</a><ul>
<li class="chapter" data-level="4.1" data-path="seminar4.html"><a href="seminar4.html#seminar-3"><i class="fa fa-check"></i><b>4.1</b> Seminar</a><ul>
<li class="chapter" data-level="4.1.1" data-path="seminar4.html"><a href="seminar4.html#the-standard-error"><i class="fa fa-check"></i><b>4.1.1</b> The Standard Error</a></li>
<li class="chapter" data-level="4.1.2" data-path="seminar4.html"><a href="seminar4.html#t-test-one-sample-hypothesis-test"><i class="fa fa-check"></i><b>4.1.2</b> T-test (one sample hypothesis test)</a></li>
<li class="chapter" data-level="4.1.3" data-path="seminar4.html"><a href="seminar4.html#t-test-difference-in-means"><i class="fa fa-check"></i><b>4.1.3</b> T-test (difference in means)</a></li>
<li class="chapter" data-level="4.1.4" data-path="seminar4.html"><a href="seminar4.html#estimating-p-values-from-t-values"><i class="fa fa-check"></i><b>4.1.4</b> Estimating p values from t values</a></li>
<li class="chapter" data-level="4.1.5" data-path="seminar4.html"><a href="seminar4.html#exercises-3"><i class="fa fa-check"></i><b>4.1.5</b> Exercises</a></li>
<li class="chapter" data-level="4.1.6" data-path="seminar4.html"><a href="seminar4.html#optional-exercises-that-require-reading-extra-info-below"><i class="fa fa-check"></i><b>4.1.6</b> Optional Exercises that require reading Extra Info below</a></li>
<li class="chapter" data-level="4.1.7" data-path="seminar4.html"><a href="seminar4.html#advanced-exercises"><i class="fa fa-check"></i><b>4.1.7</b> Advanced Exercises</a></li>
<li class="chapter" data-level="4.1.8" data-path="seminar4.html"><a href="seminar4.html#extra-info"><i class="fa fa-check"></i><b>4.1.8</b> Extra Info</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="solutions4.html"><a href="solutions4.html"><i class="fa fa-check"></i><b>4.2</b> Solutions</a><ul>
<li class="chapter" data-level="4.2.1" data-path="solutions4.html"><a href="solutions4.html#optional-exercises-that-require-reading-extra-info-below-1"><i class="fa fa-check"></i><b>4.2.1</b> Optional Exercises that require reading Extra Info below</a></li>
<li class="chapter" data-level="4.2.2" data-path="solutions4.html"><a href="solutions4.html#advanced-exercises-1"><i class="fa fa-check"></i><b>4.2.2</b> Advanced Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="seminar5.html"><a href="seminar5.html"><i class="fa fa-check"></i><b>5</b> Revision: Sample Variance and Sample Standard Deviation; Hypothesis testing and Confidence Intervals</a><ul>
<li class="chapter" data-level="5.1" data-path="seminar5.html"><a href="seminar5.html#seminar-4"><i class="fa fa-check"></i><b>5.1</b> Seminar</a><ul>
<li class="chapter" data-level="5.1.1" data-path="seminar5.html"><a href="seminar5.html#sample-variance-and-sample-standard-deviation"><i class="fa fa-check"></i><b>5.1.1</b> Sample Variance and Sample Standard Deviation</a></li>
<li class="chapter" data-level="5.1.2" data-path="seminar5.html"><a href="seminar5.html#t-test-for-the-sample-mean"><i class="fa fa-check"></i><b>5.1.2</b> T test for the sample mean</a></li>
<li class="chapter" data-level="5.1.3" data-path="seminar5.html"><a href="seminar5.html#t-test-for-the-difference-in-means"><i class="fa fa-check"></i><b>5.1.3</b> T test for the difference in means</a></li>
<li class="chapter" data-level="5.1.4" data-path="seminar5.html"><a href="seminar5.html#exercises-4"><i class="fa fa-check"></i><b>5.1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="solutions5.html"><a href="solutions5.html"><i class="fa fa-check"></i><b>5.2</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="seminar6.html"><a href="seminar6.html"><i class="fa fa-check"></i><b>6</b> Bivariate linear regression models</a><ul>
<li class="chapter" data-level="6.1" data-path="seminar6.html"><a href="seminar6.html#seminar-5"><i class="fa fa-check"></i><b>6.1</b> Seminar</a><ul>
<li class="chapter" data-level="6.1.1" data-path="seminar6.html"><a href="seminar6.html#packages"><i class="fa fa-check"></i><b>6.1.1</b> Packages</a></li>
<li class="chapter" data-level="6.1.2" data-path="seminar6.html"><a href="seminar6.html#fitted-values"><i class="fa fa-check"></i><b>6.1.2</b> Fitted values</a></li>
<li class="chapter" data-level="6.1.3" data-path="seminar6.html"><a href="seminar6.html#additional-resources"><i class="fa fa-check"></i><b>6.1.3</b> Additional Resources</a></li>
<li class="chapter" data-level="6.1.4" data-path="seminar6.html"><a href="seminar6.html#exercises-5"><i class="fa fa-check"></i><b>6.1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="solutions6.html"><a href="solutions6.html"><i class="fa fa-check"></i><b>6.2</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="seminar7.html"><a href="seminar7.html"><i class="fa fa-check"></i><b>7</b> Multiple linear regression models (I)</a><ul>
<li class="chapter" data-level="7.1" data-path="seminar7.html"><a href="seminar7.html#seminar-6"><i class="fa fa-check"></i><b>7.1</b> Seminar</a><ul>
<li class="chapter" data-level="7.1.1" data-path="seminar7.html"><a href="seminar7.html#loading-understanding-and-cleaning-our-data"><i class="fa fa-check"></i><b>7.1.1</b> Loading, Understanding and Cleaning our Data</a></li>
<li class="chapter" data-level="7.1.2" data-path="seminar7.html"><a href="seminar7.html#estimating-a-bivariate-regression"><i class="fa fa-check"></i><b>7.1.2</b> Estimating a Bivariate Regression</a></li>
<li class="chapter" data-level="7.1.3" data-path="seminar7.html"><a href="seminar7.html#multivariate-regression"><i class="fa fa-check"></i><b>7.1.3</b> Multivariate Regression</a></li>
<li class="chapter" data-level="7.1.4" data-path="seminar7.html"><a href="seminar7.html#joint-significance-test-f-statistic"><i class="fa fa-check"></i><b>7.1.4</b> Joint Significance Test (F-statistic)</a></li>
<li class="chapter" data-level="7.1.5" data-path="seminar7.html"><a href="seminar7.html#predicting-outcome-conditional-on-institutional-quality"><i class="fa fa-check"></i><b>7.1.5</b> Predicting outcome conditional on institutional quality</a></li>
<li class="chapter" data-level="7.1.6" data-path="seminar7.html"><a href="seminar7.html#additional-resources-1"><i class="fa fa-check"></i><b>7.1.6</b> Additional Resources</a></li>
<li class="chapter" data-level="7.1.7" data-path="seminar7.html"><a href="seminar7.html#exercises-6"><i class="fa fa-check"></i><b>7.1.7</b> Exercises</a></li>
<li class="chapter" data-level="7.1.8" data-path="seminar7.html"><a href="seminar7.html#midterm-preparation"><i class="fa fa-check"></i><b>7.1.8</b> Midterm Preparation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="solutions7.html"><a href="solutions7.html"><i class="fa fa-check"></i><b>7.2</b> Solutions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="seminar8.html"><a href="seminar8.html"><i class="fa fa-check"></i><b>8</b> Multiple linear regression models (II)</a><ul>
<li class="chapter" data-level="8.1" data-path="seminar8.html"><a href="seminar8.html#seminar-7"><i class="fa fa-check"></i><b>8.1</b> Seminar</a><ul>
<li class="chapter" data-level="8.1.1" data-path="seminar8.html"><a href="seminar8.html#loading-data-1"><i class="fa fa-check"></i><b>8.1.1</b> Loading Data</a></li>
<li class="chapter" data-level="8.1.2" data-path="seminar8.html"><a href="seminar8.html#r-squared"><i class="fa fa-check"></i><b>8.1.2</b> R Squared</a></li>
<li class="chapter" data-level="8.1.3" data-path="seminar8.html"><a href="seminar8.html#the-relationship-between-institutional-quality-and-quality-of-life-by-colonial-past"><i class="fa fa-check"></i><b>8.1.3</b> The Relationship between Institutional Quality and Quality of Life by Colonial Past</a></li>
<li class="chapter" data-level="8.1.4" data-path="seminar8.html"><a href="seminar8.html#interactions-continuous-and-binary"><i class="fa fa-check"></i><b>8.1.4</b> Interactions: Continuous and Binary</a></li>
<li class="chapter" data-level="8.1.5" data-path="seminar8.html"><a href="seminar8.html#non-linearities"><i class="fa fa-check"></i><b>8.1.5</b> Non-Linearities</a></li>
<li class="chapter" data-level="8.1.6" data-path="seminar8.html"><a href="seminar8.html#exercises-7"><i class="fa fa-check"></i><b>8.1.6</b> Exercises</a></li>
<li class="chapter" data-level="8.1.7" data-path="seminar8.html"><a href="seminar8.html#extra-info-dummy-variables-repetition"><i class="fa fa-check"></i><b>8.1.7</b> Extra Info: Dummy Variables Repetition</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="solutions8.html"><a href="solutions8.html"><i class="fa fa-check"></i><b>8.2</b> Solutions</a><ul>
<li class="chapter" data-level="8.2.1" data-path="solutions8.html"><a href="solutions8.html#question-1"><i class="fa fa-check"></i><b>8.2.1</b> Question 1</a></li>
<li class="chapter" data-level="8.2.2" data-path="solutions8.html"><a href="solutions8.html#question-2"><i class="fa fa-check"></i><b>8.2.2</b> Question 2</a></li>
<li class="chapter" data-level="8.2.3" data-path="solutions8.html"><a href="solutions8.html#question-3"><i class="fa fa-check"></i><b>8.2.3</b> Question 3</a></li>
<li class="chapter" data-level="8.2.4" data-path="solutions8.html"><a href="solutions8.html#question-4"><i class="fa fa-check"></i><b>8.2.4</b> Question 4</a></li>
<li class="chapter" data-level="8.2.5" data-path="solutions8.html"><a href="solutions8.html#question-5"><i class="fa fa-check"></i><b>8.2.5</b> Question 5</a></li>
<li class="chapter" data-level="8.2.6" data-path="solutions8.html"><a href="solutions8.html#question-6"><i class="fa fa-check"></i><b>8.2.6</b> Question 6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="seminar9.html"><a href="seminar9.html"><i class="fa fa-check"></i><b>9</b> Regression Assumptions</a><ul>
<li class="chapter" data-level="9.1" data-path="seminar9.html"><a href="seminar9.html#seminar-8"><i class="fa fa-check"></i><b>9.1</b> Seminar</a><ul>
<li class="chapter" data-level="9.1.1" data-path="seminar9.html"><a href="seminar9.html#required-packages"><i class="fa fa-check"></i><b>9.1.1</b> Required Packages</a></li>
<li class="chapter" data-level="9.1.2" data-path="seminar9.html"><a href="seminar9.html#omitted-variable-bias"><i class="fa fa-check"></i><b>9.1.2</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="9.1.3" data-path="seminar9.html"><a href="seminar9.html#detecting-non-linearity"><i class="fa fa-check"></i><b>9.1.3</b> Detecting non-linearity</a></li>
<li class="chapter" data-level="9.1.4" data-path="seminar9.html"><a href="seminar9.html#heteroskedasticity"><i class="fa fa-check"></i><b>9.1.4</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="9.1.5" data-path="seminar9.html"><a href="seminar9.html#exercises-8"><i class="fa fa-check"></i><b>9.1.5</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="seminar10.html"><a href="seminar10.html"><i class="fa fa-check"></i><b>10</b> Panel Data - Fixed Effects and some Random Effects</a><ul>
<li class="chapter" data-level="10.1" data-path="seminar10.html"><a href="seminar10.html#seminar-9"><i class="fa fa-check"></i><b>10.1</b> Seminar</a><ul>
<li class="chapter" data-level="10.1.1" data-path="seminar10.html"><a href="seminar10.html#our-data"><i class="fa fa-check"></i><b>10.1.1</b> Our data</a></li>
<li class="chapter" data-level="10.1.2" data-path="seminar10.html"><a href="seminar10.html#unit-fixed-effects-country-fixed-effects"><i class="fa fa-check"></i><b>10.1.2</b> Unit fixed effects (country fixed effects)</a></li>
<li class="chapter" data-level="10.1.3" data-path="seminar10.html"><a href="seminar10.html#time-fixed-effects"><i class="fa fa-check"></i><b>10.1.3</b> Time fixed effects</a></li>
<li class="chapter" data-level="10.1.4" data-path="seminar10.html"><a href="seminar10.html#twoway-fixed-effects"><i class="fa fa-check"></i><b>10.1.4</b> Twoway fixed effects</a></li>
<li class="chapter" data-level="10.1.5" data-path="seminar10.html"><a href="seminar10.html#serial-correlationauto-correlation"><i class="fa fa-check"></i><b>10.1.5</b> Serial correlation/auto-correlation</a></li>
<li class="chapter" data-level="10.1.6" data-path="seminar10.html"><a href="seminar10.html#cross-sectional-dependence-spatial-dependence"><i class="fa fa-check"></i><b>10.1.6</b> Cross-sectional dependence/ spatial dependence</a></li>
<li class="chapter" data-level="10.1.7" data-path="seminar10.html"><a href="seminar10.html#the-random-effects-model"><i class="fa fa-check"></i><b>10.1.7</b> The random effects model</a></li>
<li class="chapter" data-level="10.1.8" data-path="seminar10.html"><a href="seminar10.html#more-guns-less-crime"><i class="fa fa-check"></i><b>10.1.8</b> More guns, less crime</a></li>
<li class="chapter" data-level="10.1.9" data-path="seminar10.html"><a href="seminar10.html#question-1-1"><i class="fa fa-check"></i><b>10.1.9</b> Question 1</a></li>
<li class="chapter" data-level="10.1.10" data-path="seminar10.html"><a href="seminar10.html#question-2-1"><i class="fa fa-check"></i><b>10.1.10</b> Question 2</a></li>
<li class="chapter" data-level="10.1.11" data-path="seminar10.html"><a href="seminar10.html#question-3-1"><i class="fa fa-check"></i><b>10.1.11</b> Question 3</a></li>
<li class="chapter" data-level="10.1.12" data-path="seminar10.html"><a href="seminar10.html#question-4-1"><i class="fa fa-check"></i><b>10.1.12</b> Question 4</a></li>
<li class="chapter" data-level="10.1.13" data-path="seminar10.html"><a href="seminar10.html#question-5-1"><i class="fa fa-check"></i><b>10.1.13</b> Question 5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="seminar11.html"><a href="seminar11.html"><i class="fa fa-check"></i><b>11</b> Binary Dependent Varible Models</a><ul>
<li class="chapter" data-level="11.1" data-path="seminar11.html"><a href="seminar11.html#seminar-10"><i class="fa fa-check"></i><b>11.1</b> Seminar</a><ul>
<li class="chapter" data-level="11.1.1" data-path="seminar11.html"><a href="seminar11.html#required-packages-1"><i class="fa fa-check"></i><b>11.1.1</b> Required Packages</a></li>
<li class="chapter" data-level="11.1.2" data-path="seminar11.html"><a href="seminar11.html#loading-data-2"><i class="fa fa-check"></i><b>11.1.2</b> Loading Data</a></li>
<li class="chapter" data-level="11.1.3" data-path="seminar11.html"><a href="seminar11.html#linear-regression-with-a-binary-dependent-variable"><i class="fa fa-check"></i><b>11.1.3</b> Linear regression with a Binary Dependent Variable</a></li>
<li class="chapter" data-level="11.1.4" data-path="seminar11.html"><a href="seminar11.html#logistic-regression-model"><i class="fa fa-check"></i><b>11.1.4</b> Logistic Regression Model</a></li>
<li class="chapter" data-level="11.1.5" data-path="seminar11.html"><a href="seminar11.html#odds-ratios"><i class="fa fa-check"></i><b>11.1.5</b> Odds-ratios</a></li>
<li class="chapter" data-level="11.1.6" data-path="seminar11.html"><a href="seminar11.html#predicted-probabilities"><i class="fa fa-check"></i><b>11.1.6</b> Predicted probabilities</a></li>
<li class="chapter" data-level="11.1.7" data-path="seminar11.html"><a href="seminar11.html#exercises-9"><i class="fa fa-check"></i><b>11.1.7</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="datacamp.html"><a href="datacamp.html"><i class="fa fa-check"></i><b>12</b> Datacamp</a><ul>
<li class="chapter" data-level="12.1" data-path="datacamp.html"><a href="datacamp.html#develop-your-skills-as-a-data-scientist"><i class="fa fa-check"></i><b>12.1</b> Develop your skills as a data scientist</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics 1</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="binary-dependent-varible-models" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Binary Dependent Varible Models</h1>
<div id="seminar-10" class="section level2">
<h2><span class="header-section-number">11.1</span> Seminar</h2>
<div id="required-packages-1" class="section level3">
<h3><span class="header-section-number">11.1.1</span> Required Packages</h3>
<p>Let’s start by loading the required packages:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(foreign) 
<span class="kw">library</span>(texreg) 
<span class="kw">library</span>(lmtest)
<span class="kw">library</span>(sandwich)</code></pre></div>
<p>Clear the environment</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(<span class="dt">list =</span> <span class="kw">ls</span>())</code></pre></div>
</div>
<div id="loading-data-2" class="section level3">
<h3><span class="header-section-number">11.1.2</span> Loading Data</h3>
<p>We will be using data from the Afrobarometer (a public attitude survey on democracy and governance in more than 35 countries in Africa) to investigate whether a political candidate can utilize his wife’s ethnicity to garner coethnic support. This is linked to a broad research theory which implies that voters in Africa prefer to vote for candidates of their own ethnic group, and that if a presidential candidate marries a non-coethnic wife, this may broaden their electoral appeal to other ethnic groups.</p>
<p>We will focus only African democracies where the president and wife are not of the same ethnicity are considered (i.e., the president and wife are not coethnic with one another). We will investigate whether voters are more likely to vote for the a president when the voter shares the same ethnicity as the president’s wife.</p>
<p>First, let’s load the data directly from GitHub:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">afb &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/UCLSPP/datasets/master/data/afb_class.csv&quot;</span>)</code></pre></div>
<p>The table below gives an overview of the variables included in the data.</p>
<table>
<colgroup>
<col width="10%" />
<col width="89%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>country</code></td>
<td align="left">A character variable indicating the country of the respondent</td>
</tr>
<tr class="even">
<td align="left"><code>wifecoethnic</code></td>
<td align="left">1 if respondent is same ethnicity as president’s wife, and 0 otherwise</td>
</tr>
<tr class="odd">
<td align="left"><code>oppcoethnic</code></td>
<td align="left">1 if respondent is same ethnicity as main presidential opponent, and 0 otherwise</td>
</tr>
<tr class="even">
<td align="left"><code>ethnicpercent</code></td>
<td align="left">Respondent’s ethnic group fraction in respondent country</td>
</tr>
<tr class="odd">
<td align="left"><code>distance</code></td>
<td align="left">Distance between respondent’s home and the home city of the president (measured in hundreds of miles)</td>
</tr>
<tr class="even">
<td align="left"><code>vote</code></td>
<td align="left">1 if respondent would vote for the president, 0 otherwise</td>
</tr>
</tbody>
</table>
<p>Now take a look at the first few observations to see what the dataset looks like</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(afb)</code></pre></div>
<pre><code>  country wifecoethnic oppcoethnic ethnicpercent vote  distance
1   benin            1           1     0.4173623    1  5.449764
2   benin            1           1     0.4173623    0 18.510687
3   benin            1           1     0.4173623    0 26.370297
4   benin            1           1     0.4173623    0 21.012341
5   benin            1           1     0.4173623    0 22.238316
6   benin            1           1     0.4173623    1  1.822167</code></pre>
</div>
<div id="linear-regression-with-a-binary-dependent-variable" class="section level3">
<h3><span class="header-section-number">11.1.3</span> Linear regression with a Binary Dependent Variable</h3>
<p>Before moving on to the new model, we can illustrate some of the shortcomings of the linear regression model when working with binary outcome variables.</p>
<p>Let’s run a linear regression (here, a <em>linear probability model</em>) where <code>vote</code> is our dependent variable, and <code>distance</code> is our independent variable. Try doing this yourself before revealing the solution code below.</p>
<div class="sourceCode"><pre class="sourceCode r collapsible"><code class="sourceCode r">linear_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(vote <span class="op">~</span><span class="st"> </span>distance, <span class="dt">data =</span> afb)
<span class="kw">screenreg</span>(linear_mod)</code></pre></div>
<pre><code>
========================
             Model 1    
------------------------
(Intercept)     1.33 ***
               (0.01)   
distance       -0.06 ***
               (0.00)   
------------------------
R^2             0.70    
Adj. R^2        0.70    
Num. obs.    4552       
RMSE            0.27    
========================
*** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05</code></pre>
<p>The model shows that there is a strong and significant bivariate relationship between distance and vote choice for the president. Specifically, the model suggest that increasing the distance between the respondent and the president’s home city by 100 miles decreases the probability that the respondent will vote for the president by 6 percentage points on average.</p>
<p>As we discussed in lecture, however, the linear probability model can lead to some odd conclusions with regard to fitted values. Let’s plot the two variables above, and include the estimated regression line.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(
  <span class="dt">x =</span> afb<span class="op">$</span>distance,
  <span class="dt">y =</span> afb<span class="op">$</span>vote,
  <span class="dt">pch =</span> <span class="dv">19</span>,
  <span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>,
  <span class="dt">xlab =</span> <span class="st">&quot;Distance&quot;</span>, 
  <span class="dt">ylab =</span> <span class="st">&quot;Vote for the president&quot;</span>,
  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span>.<span class="dv">5</span>, <span class="fl">1.5</span>),
  <span class="dt">frame.plot =</span> F)
<span class="kw">abline</span>(linear_mod, <span class="dt">lwd =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="statistics1_files/figure-html/unnamed-chunk-484-1.png" width="672" /></p>
<p>As we can see from the plot, because the functional form of the linear probability model is linear, the estimated relationsip suggests that for respondents with a <code>distance</code> value greater than about 23 have a <em>negative</em> probability of voting for the president, and respondents with a <code>distance</code> value less than about 5 have a probability of voting for the president that is <em>greater than 1</em>.</p>
<div id="adjusted-standard-errors-in-the-linear-probability-model" class="section level4">
<h4><span class="header-section-number">11.1.3.1</span> Adjusted Standard Errors in the Linear Probability Model</h4>
<p>Now create a plot of the residuals from the model on the Y-axis, and the <code>distance</code> variable on the X-axis. Try this yourself before revealing the code below.</p>
<div class="sourceCode"><pre class="sourceCode r collapsible"><code class="sourceCode r"><span class="kw">plot</span>(
  <span class="dt">x =</span> afb<span class="op">$</span>distance, 
  <span class="dt">y =</span> <span class="kw">residuals</span>(linear_mod), 
  <span class="dt">pch =</span> <span class="dv">19</span>,
  <span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>,
  <span class="dt">xlab =</span> <span class="st">&quot;Distance&quot;</span>, 
  <span class="dt">ylab =</span> <span class="st">&quot;Residuals&quot;</span>,
  <span class="dt">frame.plot =</span> F)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lwd =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="statistics1_files/figure-html/unnamed-chunk-485-1.png" width="672" /></p>
<p>We can see from this plot that the linear probability model is always heteroskedastic – the errors are not evenly distributed around zero for all values of <code>distance</code>.</p>
<p>Because of this problem, we now adjust the standard errors to be heteroskedasticity robust.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">corrected_errors &lt;-<span class="st"> </span><span class="kw">coeftest</span>(linear_mod, <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(linear_mod))
<span class="kw">screenreg</span>(<span class="kw">list</span>(linear_mod,corrected_errors))</code></pre></div>
<pre><code>
===================================
             Model 1      Model 2  
-----------------------------------
(Intercept)     1.33 ***   1.33 ***
               (0.01)     (0.01)   
distance       -0.06 ***  -0.06 ***
               (0.00)     (0.00)   
-----------------------------------
R^2             0.70               
Adj. R^2        0.70               
Num. obs.    4552                  
RMSE            0.27               
===================================
*** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05</code></pre>
<p>In this instance, the adjustment did not change our substantial conclusion. However, we still always need to adjust standard errors when we estimate the linear probability model.</p>
</div>
<div id="classification" class="section level4">
<h4><span class="header-section-number">11.1.3.2</span> Classification</h4>
<p>Our binary variable is either 0 or 1. With the linear probability model, we predict the underlying (and fundamentally unobserved) probability that the outcome is 0 or 1. In order to decide whether an outcome is 0 or 1, we follow a simple rule: Every outcome with a probability of greater or equal 0.5 is assigned a 1 and a 0 otherwise. First, we create a new variable called <code>lm_pps</code>. Those are our model predictions or fitted values. They are predicted probabilities that the outcome is 1 - with the downside that we can get predictions outsied the 0 to 1 interval.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predicted probabilities</span>
afb<span class="op">$</span>lm_yhats &lt;-<span class="st"> </span>linear_mod<span class="op">$</span>fitted.values
<span class="kw">summary</span>(afb<span class="op">$</span>lm_pps)</code></pre></div>
<pre><code>Length  Class   Mode 
     0   NULL   NULL </code></pre>
<p>Let’s turn our predictions into outcomes of either 0 or 1 using the <code>ifelse()</code> function. The first argument of the function is a logical condition that is true or false for every observation that is evaluated. The second argument specifies what to do if the condition is true and third argument specifies what to do if the condition is not met (false).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># expected values</span>
afb<span class="op">$</span>exp.vals &lt;-<span class="st"> </span><span class="kw">ifelse</span>( afb<span class="op">$</span>lm_yhats <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dt">yes =</span> <span class="dv">1</span>, <span class="dt">no =</span> <span class="dv">0</span> )
<span class="kw">table</span>(afb<span class="op">$</span>exp.vals)</code></pre></div>
<pre><code>
   0    1 
2066 2486 </code></pre>
<p>We predict 2066 zeroes and 2486 ones. How good is this. We cannot use R^2 as a model fit statistic for models with binary dependent variables. It is impossible that all values are on the regression line. Let’s examine the outcome variable <code>vote</code> first.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(afb<span class="op">$</span>vote)</code></pre></div>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  0.0000  1.0000  0.5464  1.0000  1.0000 </code></pre>
<p>The mean is ~0.55. Therefore, 55 per cent of the respondents would vote for the president. It also means that a classification model must be better than predicting 55 per cent of the outcomes correctly. Otherwise, it is no better than the naive guess.</p>
<p>What is the naive guess? It is simply the modal category. In our case, it is 1 because 55 per cent of the respondents would vote for the president and 45 would not.</p>
<p>If our model does not predict more than 55 per cent of outcomes correctly, it makes no contribution. We must always pass this minimum test. Let’s compare actual outcomes to our expected values (the predictions from our model).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out.table &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="dt">prediction =</span> afb<span class="op">$</span>exp.vals, <span class="dt">truth =</span> afb<span class="op">$</span>vote)
out.table</code></pre></div>
<pre><code>          truth
prediction    0    1
         0 1922  144
         1  143 2343</code></pre>
<p>On the diagonal, we see the correct predictions and on the off-diagonal, we see the errors. If we sum up the diagonal and divide by the total, we get the per cent correctly classified. Recall, it must be larger than 55 per cent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># per cent correctly classified</span>
cc.lm &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(out.table)) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(out.table)
cc.lm</code></pre></div>
<pre><code>[1] 0.9369508</code></pre>
<p>The mdoel does extremely well. We correctly classify 94 of all cases. A substantial improvement on the naive guess. Let’s move on and compare our linear model to the logistic regression approach.</p>
</div>
</div>
<div id="logistic-regression-model" class="section level3">
<h3><span class="header-section-number">11.1.4</span> Logistic Regression Model</h3>
<p>We use the generalized linear model function <code>glm()</code> to estimate a logistic regression. The syntax is very similar to the <code>lm</code> regression function that we are already familiar with, but there is an additional argument that we need to specify (the <code>family</code> argument) in order to tell R that we would like to estimate a logistic regression model.</p>
<table style="width:96%;">
<colgroup>
<col width="12%" />
<col width="83%" />
</colgroup>
<thead>
<tr class="header">
<th>Argument</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>formula</code></td>
<td>As before, the <code>formula</code> describes the relationship between the dependent and independent variables, for example <code>dependent.variable ~ independent.variable</code> <br> In our case, we will use the formula: <code>vote ~ wifecoethnic + distance</code></td>
</tr>
<tr class="even">
<td><code>data</code></td>
<td>Again as before, this is simply the name of the dataset that contains the variable of interest. In our case, this is the dataset called <code>afb</code>.</td>
</tr>
<tr class="odd">
<td><code>family</code></td>
<td>The <code>family</code> argument provides a description of the error distribution and link function to be used in the model. For our purposes, we would like to estimate a binary logistic regression model and so we set <code>family = binomial(link = &quot;logit&quot;)</code></td>
</tr>
</tbody>
</table>
<p>We tell <code>glm()</code> that we’ve binary dependent variable and we want to use the logistic link function using the <code>family = binomial(link = &quot;logit&quot;)</code> argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">logit_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(vote <span class="op">~</span><span class="st"> </span>wifecoethnic <span class="op">+</span><span class="st"> </span>distance,
                     <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), <span class="dt">data =</span> afb)
<span class="kw">screenreg</span>(logit_model_<span class="dv">1</span>)</code></pre></div>
<pre><code>
===========================
                Model 1    
---------------------------
(Intercept)       11.66 ***
                  (0.42)   
wifecoethnic      -1.36 ***
                  (0.17)   
distance          -0.79 ***
                  (0.03)   
---------------------------
AIC             1364.65    
BIC             1383.92    
Log Likelihood  -679.33    
Deviance        1358.65    
Num. obs.       4552       
===========================
*** p &lt; 0.001, ** p &lt; 0.01, * p &lt; 0.05</code></pre>
<p>Interpreting the output of a logistic regression model is less straightforward than for the linear model, because the coefficients no longer describe the effect of a unit change in X on Y. Instead, the direct interpretation of the coefficient is: a one unit change in X is associated with a <span class="math inline">\(\hat{\beta}\)</span> change in the log-odds of Y, holding constant other variables. Here, the coefficient on <code>wifecoethnic</code> is equal to -1.36, implying that the log-odds of voting for the president are 1.36 <em>lower</em> when the respondent has the same ethnicity as the president’s wife, holding constant distance.</p>
<p>The interpretation of the significance of the coefficients remains unchanged from the linear regression model. For example, the standard error for the coefficient on <code>wifecoethnic</code> is 0.17, and the test statistic is therefore -1.36/0.17 = -8. This is much greater than the critical value of any conventionally used <span class="math inline">\(\alpha\)</span>-level and so we can be sure that this result is statistically significant. We will speak more about statistical inference for logit coefficients next week.</p>
</div>
<div id="odds-ratios" class="section level3">
<h3><span class="header-section-number">11.1.5</span> Odds-ratios</h3>
<p>Differences in the log-odds, however, are difficult to interpret substantively. There are two main approaches to describing the substantive relationships that emerge from a logistic regression model. 1) odds-ratios, and 2) predicted probabilities.</p>
<p>Converting log-odds differences to odds-ratios is very straightforward. As the log function is the inverse of the exponential function, we can simply exponentiate the coefficient associated with <code>wifecoethnic</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_wifecoethnic &lt;-<span class="st"> </span><span class="kw">coef</span>(logit_model_<span class="dv">1</span>)[[<span class="st">&quot;wifecoethnic&quot;</span>]]
<span class="kw">exp</span>(beta_wifecoethnic)</code></pre></div>
<pre><code>[1] 0.2556929</code></pre>
<p>And we can do the same for the coefficient associated with <code>distance</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_distance &lt;-<span class="st"> </span><span class="kw">coef</span>(logit_model_<span class="dv">1</span>)[[<span class="st">&quot;distance&quot;</span>]]
<span class="kw">exp</span>(beta_distance)</code></pre></div>
<pre><code>[1] 0.4539435</code></pre>
<p>We can then interpret the odds-ratios as follows:</p>
<ul>
<li>When the respondent shares the same ethnicity as the president’s wife the odds of voting for the president are multiplied by 0.26, holding constant the distance between the respondent and the president’s home city (i.e. they decrease by 74%)</li>
<li>Increasing the distance between the respondent and the president’s home city by 100 miles, holding constant whether the respondent shares the same ethnicity as the president’s wife, multiplies the odds of voting for the president by 0.45, (i.e. the odds decrease by 55%)</li>
<li>In general, when X increases by one unit, the odds of the outcome <span class="math inline">\(Y = 1\)</span> are multiplied by <span class="math inline">\(exp(\hat{\beta})\)</span>, holding other factors constant</li>
</ul>
</div>
<div id="predicted-probabilities" class="section level3">
<h3><span class="header-section-number">11.1.6</span> Predicted probabilities</h3>
<p>Thinking in terms of odds may not be much better than thinking in terms of log-odds, and so often the most useful discussion of the substantive effect sizes is in terms of predicted probabilities.</p>
<p>We can use the <code>predict()</code> function to calculate fitted values for the logistic regression model, just as we did for the linear model. Here, however, we need to take into account the fact that we model the <em>log-odds</em> that <span class="math inline">\(Y = 1\)</span>, rather than the <em>probability</em> that <span class="math inline">\(Y=1\)</span>. The <code>predict()</code> function will therefore, by default, give us predictions for Y on the log-odds scale. To get predictions on the probability scale, we need to add an additional argument to <code>predict()</code>: we set the <code>type</code> argument to <code>type = &quot;response&quot;</code>.</p>
<p>For example, if we would like to calculate the predicted probability of voting for the president for a respondent who shares the same ethnicity as the president’s wife, and lives 1000 miles from the president’s home city, we could use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_prob_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">1</span>, <span class="dt">distance =</span> <span class="dv">10</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
pred_prob_<span class="dv">1</span></code></pre></div>
<pre><code>      1 
0.91698 </code></pre>
<p>The tells us that the probability of a respondent with these covariate values voting for the president (<span class="math inline">\(Y=1\)</span>) is 0.92, based on this model.</p>
<p><strong>At home</strong>, we want you to estimate the predicted probability for this scenario by doing the transformation yourself. You can compare your results with the code below</p>
<div class="sourceCode"><pre class="sourceCode r collapsible"><code class="sourceCode r"><span class="co"># get fitted values using predict function - not transformed back to probabilities</span>
pred_prob_1a &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">1</span>, <span class="dt">distance =</span> <span class="dv">10</span>))
pred_prob_1a</code></pre></div>
<pre><code>       1 
2.402004 </code></pre>
<div class="sourceCode"><pre class="sourceCode r collapsible"><code class="sourceCode r"><span class="co"># send the fitted values through the link function</span>
<span class="kw">exp</span>(pred_prob_1a) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(pred_prob_1a))</code></pre></div>
<pre><code>      1 
0.91698 </code></pre>
<div class="sourceCode"><pre class="sourceCode r collapsible"><code class="sourceCode r"><span class="co"># get fitted values by hand</span>
pred_prob_1b &lt;-<span class="st"> </span><span class="kw">coef</span>(logit_model_<span class="dv">1</span>)[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(logit_model_<span class="dv">1</span>)[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(logit_model_<span class="dv">1</span>)[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span><span class="dv">10</span>
<span class="co"># below we use as.numeric() only because otherwise R labels the result intercept which it is not</span>
pred_prob_1b &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(pred_prob_1b)
pred_prob_1b</code></pre></div>
<pre><code>[1] 2.402004</code></pre>
<div class="sourceCode"><pre class="sourceCode r collapsible"><code class="sourceCode r">## send fitted values through the link function
<span class="kw">exp</span>(pred_prob_1b) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(pred_prob_1b))</code></pre></div>
<pre><code>[1] 0.91698</code></pre>
<p>How does this predicted probability compare to the predicted probability of voting for the president for a respondent who <em>is not</em> coethnic with the president’s wife, and lives 1000 miles from the president’s home city? We can just use the <code>predict()</code> function again, but specify a different value for <code>wifecoethnic</code> to use for the prediction:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_prob_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">0</span>, <span class="dt">distance =</span> <span class="dv">10</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
pred_prob_<span class="dv">2</span></code></pre></div>
<pre><code>        1 
0.9773743 </code></pre>
<p>Comparing the two predicted probabilities, the model tells us that for respondents who live 100 miles from the president’s home city, sharing the ethnicity of the president’s wife <em>decreases</em> the probability of voting for the president by about 6 points:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_prob_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>pred_prob_<span class="dv">2</span></code></pre></div>
<pre><code>         1 
-0.0603943 </code></pre>
<p>Notice that this “finding” is the opposite of the prediction from the theory: respondents do not seem to be more likely to vote for the president if they share the same ethnicity as the president’s wife. Of course, here we are dealing with a very simple model with many possible confounding variables that we have not included in the model!</p>
<p>As discussed in lecture, the logistic model implies a <em>non-linear</em> relationship between the X variables and the outcome. To see this more clearly, we can calulate the probability of voting for the president over the entire range of the <code>distance</code> variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Set the values for the explanatory variables
data_for_predicted_prob &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">distance =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">34</span>, <span class="dt">by =</span> .<span class="dv">5</span>),
                                     <span class="dt">wifecoethnic =</span> <span class="dv">1</span>
                                     )</code></pre></div>
<p>Here, we have set the <code>distance</code> variable to vary between 0 and 34, with increments of .5 units and we have set <code>wifecoethnic</code> to be equal to 1. We have then put all of these values into a new <code>data.frame</code> called <code>data_for_predicted_prob</code> which we will pass to the <code>predict()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the fitted values</span>
predicted_probs &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> data_for_predicted_prob, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)

## Save the fitted values as a new variable in the data_for_fitted_values object
data_for_predicted_prob<span class="op">$</span>predicted_probs &lt;-<span class="st"> </span>predicted_probs</code></pre></div>
<p>Finally, we can plot these values:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(
  predicted_probs <span class="op">~</span><span class="st"> </span>distance, <span class="co"># Specify the formula for the plot (dependent.variable ~ independent.variable)</span>
  <span class="dt">data =</span> data_for_predicted_prob, <span class="co"># Specify the data to use for the plot</span>
  <span class="dt">xlab =</span> <span class="st">&quot;Distance&quot;</span>, <span class="co"># Specify the X-axis title</span>
  <span class="dt">ylab =</span> <span class="st">&quot;Probability of voting for the president&quot;</span>, <span class="co"># Specify the Y-axis title</span>
  <span class="dt">frame.plot =</span> <span class="ot">FALSE</span>, <span class="co"># The frame.plot = FALSE argument removes the box from around the plot</span>
  <span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="co"># The col argument specifies the color</span>
  <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="co"># type = &quot;l&quot; will produce a line plot, rather than the default scatter plot</span>
  <span class="dt">lwd =</span> <span class="dv">3</span> <span class="co"># lwd = 3 will increase the thinkness of the line on the plot</span>
)</code></pre></div>
<p><img src="statistics1_files/figure-html/unnamed-chunk-501-1.png" width="672" /></p>
<p>The plot nicely illustrates the non-linear functional form of the logistic regression model. As desired, all of the predicted probabilities now vary between 0 and 1, as the line takes on a distinctive “S” shape. It is clear from this plot that X (<code>distance</code>) is non-linearly related to the probability that <span class="math inline">\(Y=1\)</span> (<span class="math inline">\(P(Y = 1) = \pi\)</span>): the same change in X results in difference changes in <span class="math inline">\(\pi\)</span> depending on which values of X we consider. For example:</p>
<ul>
<li>Increasing <code>distance</code> from 5 to 10 leads to a decrease in <span class="math inline">\(\pi\)</span> of only a very small amount</li>
<li>Increasing <code>distance</code> from 10 to 15 leads to a decrease in <span class="math inline">\(\pi\)</span> of a very large amount</li>
</ul>
<p>This is why we are unable to interpret the <span class="math inline">\(\beta\)</span> coefficients from the logistic model as constant increases or decreases in <span class="math inline">\(\pi\)</span> given a change in X. For any given change in X, the amount that <span class="math inline">\(\pi\)</span> will change will depend on the starting value of X that we are considering.</p>
<p>Finally, we can also see the non-linearity inherent in the logistic model by calculating the difference in predicted probability between respondents who share the ethnic group of the president’s wife and respondents who come from different ethnic groups than the president’s wife, <em>at different values of the <code>distance</code> variable</em>. Let’s calculate this difference for <code>distance = 10</code> and <code>distance = 12</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob_coethnic_dist10 &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">1</span>, <span class="dt">distance =</span> <span class="dv">10</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
prob_not_coethnic_dist10 &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">0</span>, <span class="dt">distance =</span> <span class="dv">10</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
prob_coethnic_dist10 <span class="op">-</span><span class="st"> </span>prob_not_coethnic_dist10</code></pre></div>
<pre><code>         1 
-0.0603943 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob_coethnic_dist12 &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">1</span>, <span class="dt">distance =</span> <span class="dv">12</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
prob_not_coethnic_dist12 &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">wifecoethnic =</span> <span class="dv">0</span>, <span class="dt">distance =</span> <span class="dv">12</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
prob_coethnic_dist12 <span class="op">-</span><span class="st"> </span>prob_not_coethnic_dist12</code></pre></div>
<pre><code>         1 
-0.2042512 </code></pre>
<p>The results indicating that, when comparing respondents with values of 10 on the district variable, coethnics of the president’s wife are 6 points less likey to vote for the president than non-coethnics. However, when comparing respondents with values of 12 on the distance variable, coethnics are 20 points less likely to vote for the president. Therefore, this illustrates that in a multiple logistic regression model the change in <span class="math inline">\(\pi\)</span> in response to even exactly the same change in one X variable depends on the values at which the other X variables are fixed.</p>
</div>
<div id="exercises-9" class="section level3">
<h3><span class="header-section-number">11.1.7</span> Exercises</h3>
<p>We will be using some data from a post-referendum survey among people living in Switzerland. The survey was carried out right after the vote on an initiative whether to ban military assault rifles in private households or not. If you would like to get some more background you may consult the wikipedia article on the referendum, <a href="http://en.wikipedia.org/wiki/Swiss_gun_control_referendum,_2011">here</a>.</p>
<p>You can load the data from GitHub by running the following code</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(foreign)
swiss &lt;-<span class="st"> </span><span class="kw">read.dta</span>(<span class="st">&quot;https://raw.githubusercontent.com/UCLSPP/datasets/master/data/SwissData2011.dta&quot;</span>)</code></pre></div>
<p>We have access to the following variables:</p>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VoteYes</td>
<td>1 if someone voted yes and is 0 if someone voted no.</td>
</tr>
<tr class="even">
<td>participation</td>
<td>1 for people that voted and 0 otherwise.</td>
</tr>
<tr class="odd">
<td>male</td>
<td>1 for men and 0 for women.</td>
</tr>
<tr class="even">
<td>age</td>
<td>Age in years.</td>
</tr>
<tr class="odd">
<td>LeftRight</td>
<td>Left-Right self placement where low values indicate that a respondent is more to the left.</td>
</tr>
<tr class="even">
<td>GovTrust</td>
<td>Trust in government. Little or no trust is -1, neither YES nor NO is 0, and +1 if somebody trusts the government.</td>
</tr>
<tr class="odd">
<td>ReligFreq</td>
<td>How frequently does a respondent attend a religious service? Never (0), only on special occasions (1), several times a year (2), once a month (3), and once a week (4).</td>
</tr>
<tr class="even">
<td>university</td>
<td>Binary indicator (dummy) whether respondent has a university degree (1) or not (0).</td>
</tr>
<tr class="odd">
<td>party</td>
<td>Indicates which party a respondent supports. Liberals (1), Christian Democrats (2), Social Democrats (3), Conservative Right (4), and Greens (5).</td>
</tr>
<tr class="even">
<td>income</td>
<td>Income measured in ten different brackets (higher values indicate higher income). You may assume that this variable is an interval type measure.</td>
</tr>
<tr class="odd">
<td>german</td>
<td>Binary indicator (dummy) whether respondent’s mother tongue is German (1) or not (0)</td>
</tr>
<tr class="even">
<td>suburb</td>
<td>Binary indicator (dummy) whether respondent lives in a suburban neighborhood (1) or not (0)</td>
</tr>
<tr class="odd">
<td>urban</td>
<td>Binary indicator (dummy) whether respondent lives in a city (1) or not (0)</td>
</tr>
<tr class="even">
<td>cars</td>
<td>Number of cars the respondent’s household owns.</td>
</tr>
<tr class="odd">
<td>old voter</td>
<td>Variable indicating whether a respondent is older than 60 years (1) or not (0).</td>
</tr>
<tr class="even">
<td>cantonnr</td>
<td>Variable indicating in which of the 26 Swiss cantons a respondent lives.</td>
</tr>
<tr class="odd">
<td>nodenomination</td>
<td>Share of citizens in a canton that do not have a denomination.</td>
</tr>
<tr class="even">
<td>urbanization</td>
<td>Share of citizens in a canton that live in urban areas.</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>Create plots of <code>age</code> vs <code>VoteYes</code> and <code>LeftRight</code> vs <code>VoteYes</code>. Add a regression line (from a linear probability model) to the plots</li>
<li>Estimate a model which includes <code>age</code> and <code>LeftRight</code> as predictors, and <code>VoteYes</code> as the dependent variable</li>
<li>What is the effect of a one-unit increase in <code>LeftRight</code> on <code>VoteYes</code>? Discuss in terms of odds-ratios</li>
<li>What is the effect of a one-unit increase in <code>age</code> on <code>VoteYes</code>? Discuss in terms of odds-ratios</li>
<li>What is the effect on <em>the probability of a “yes” vote</em> of moving from a left-right self placement of 5 to a self placement of 6 for an individual who is 44 years old?</li>
<li>Calculate and plot the predicted probability of voting yes across the range of the <code>age</code> variable for individuals who have a left-right self placement of 5. Do the same across the range of the <code>LeftRight</code> variable for individuals with an age of 50.</li>
<li>Looking at the other variables in the <code>swiss</code> data, which do you think might be important determinants of a “yes” vote in the referendum? Write a short paragraph justifying the importance of 3 of the predictors in <em>theoretical</em> terms. Include the additional explanatory variables you have selected in a new model that also includes <code>age</code> and <code>LeftRight</code>.</li>
<li>Provide some predicted probabilities from the model that illustrate the substantive importance of the new variables that you have added</li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="seminar10.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="datacamp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["statistics1.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
